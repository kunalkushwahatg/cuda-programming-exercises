{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWh-5M9hxYco",
        "outputId": "e3eca767-191e-4add-ee1d-d091680d5994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.11-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.2.2)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Downloading pytools-2024.1.11-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.1-cp310-cp310-linux_x86_64.whl size=662246 sha256=5282efbfe65371eebbce79473cc894bdc5ba8a1996729ae927de9789a64be0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/4a/51/d6dec3832025d601e2a365545e0972fbbeddbdb3eae72be96f\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.5 pycuda-2024.1.1 pytools-2024.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule"
      ],
      "metadata": {
        "id": "LRMXQi_CxcKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"devices : \", cuda.Device.count())\n",
        "print(\"device name : \", cuda.Device(0).name())\n",
        "\n",
        "dev = cuda.Device(0)\n",
        "print(\"compute capability : \", dev.compute_capability())\n",
        "print(\"device name : \", dev.name())\n",
        "print(\"device total memory : \", dev.total_memory() / 1024**3, \"GB\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTaxls_Fxlkd",
        "outputId": "6e3eb571-8976-4861-c517-ca2dcae35c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "devices :  1\n",
            "device name :  Tesla T4\n",
            "compute capability :  (7, 5)\n",
            "device name :  Tesla T4\n",
            "device total memory :  14.74810791015625 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for memory allocation :\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "\n",
        "for memory copy from host to devie :\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "for memory copy from device to host :\n",
        "cuda.memcpy_dtoh(a, a_gpu)\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "bk6_upoQzdq5",
        "outputId": "6f271afc-1226-4e20-8baa-30e34e1825bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor memory allocation :\\na_gpu = cuda.mem_alloc(a.nbytes)\\n\\nfor memory copy from host to devie :\\ncuda.memcpy_htod(a_gpu, a)\\n\\nfor memory copy from device to host :\\ncuda.memcpy_dtoh(a, a_gpu)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#for writing a kernel function\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void multiply(float *dest , float *a , float *b )\n",
        "{\n",
        "    const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if(idx < blockDim.x)\n",
        "    {\n",
        "        dest[idx] = a[idx] * b[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "multiply  = module.get_function(\"multiply\")\n",
        "\n",
        "a = np.random.rand(10).astype(np.float32)\n",
        "b = np.random.rand(10).astype(np.float32)\n",
        "c = np.zeros_like(a)\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "multiply(\n",
        "    cuda.Out(c),\n",
        "    cuda.In(a),\n",
        "    cuda.In(b),\n",
        "    block = (10,1,1),\n",
        "    grid = (1,1)\n",
        ")\n",
        "\n",
        "print(c)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfjC_s2_yK7L",
        "outputId": "8b82a996-f5bd-4c39-f22d-f7c0c196da22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.54707897 0.8667677  0.75203145 0.4669701  0.88215697 0.99599504\n",
            " 0.5162177  0.2081047  0.6370211  0.7753739 ]\n",
            "[0.78329396 0.6947024  0.2883797  0.04133159 0.1759537  0.53936857\n",
            " 0.47404242 0.8209888  0.24667253 0.687113  ]\n",
            "[0.42852366 0.6021456  0.2168706  0.01930062 0.15521878 0.53720844\n",
            " 0.24470909 0.17085162 0.1571356  0.53276944]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calling the fucntion\n",
        "'''\n",
        "fx = module.get_function(\"add\")\n",
        "fx(a_gpu, b_gpu, c_gpu, block = (10,1,1), grid = (1,1))\n",
        "'''\n"
      ],
      "metadata": {
        "id": "Juwm_Ilj1uXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for more info about pycuda you can refer https://documen.tician.de/pycuda/"
      ],
      "metadata": {
        "id": "PmtNzvSJ_0DR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}